{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ47Mw9+cG1KJeC1x9ni7f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishabhXYZA/Kaggle-TSS-Hack-2/blob/main/Thapar_Summer_School_Kaggel_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kaggle TSS Hack-2**\n",
        "**(Evaluation on MAE)**"
      ],
      "metadata": {
        "id": "sYhRGWhc-vii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Linear Regression**"
      ],
      "metadata": {
        "id": "uZml6HJM-6Po"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4x6CaUhRoK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49ac5b0-3e5f-459a-a828-47fd9af88d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 272.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load the training data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Define features and target\n",
        "X = train_df.drop(columns=['id', 'Row#', 'yield'])  # Input features\n",
        "y = train_df['yield']                               # Target variable\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "\n",
        "# Print MAE\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=pd.read_csv(\"test.csv\")\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "# Predict on test data\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Create submission dataframe\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_predictions\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDSPoSerSB3p",
        "outputId": "307183ea-b2fb-4ad2-e91d-ddef0cf03123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Random Forest Regressor**"
      ],
      "metadata": {
        "id": "BJ8jb9kV-_rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training data\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "\n",
        "# Prepare test data\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Initialize and train the Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training set and compute MAE\n",
        "train_predictions = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, train_predictions)\n",
        "print(f\"Mean Absolute Error on training set: {mae:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Create and save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq3I-0V7T3wV",
        "outputId": "522ca811-f5cf-48af-ccd7-fe6679f92ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on training set: 95.15\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Linear Regression with polynomial feature**"
      ],
      "metadata": {
        "id": "H3pE3Qmc_DU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training data\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "\n",
        "# Prepare test data\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Apply Polynomial Features transformation\n",
        "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Train Linear Regression on polynomial features\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_poly, y_train)\n",
        "\n",
        "# Predict on training set and calculate MAE\n",
        "train_preds = model.predict(X_train_poly)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on training set (Polynomial Regression): {mae:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test_poly)\n",
        "\n",
        "# Create submission dataframe\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zmqr7J5Ufn_",
        "outputId": "a4b811d9-37f9-4c85-9293-e83d2de37131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on training set (Polynomial Regression): 254.60\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Linear Regression with PCA and Outlier removal**"
      ],
      "metadata": {
        "id": "Re6cCkY-_KB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 1: Outlier Removal using Z-score\n",
        "# ---------------------------\n",
        "train_clean = train_df.copy()\n",
        "features = train_clean.drop(columns=['id', 'Row#', 'yield'])\n",
        "\n",
        "# Compute Z-scores and remove rows with any feature Z-score > 3\n",
        "z_scores = np.abs(zscore(features))\n",
        "train_clean = train_clean[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "# ---------------------------\n",
        "# Step 2: Prepare Data\n",
        "# ---------------------------\n",
        "X_train = train_clean.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_clean['yield']\n",
        "\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Standardize the data before PCA\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 3: Apply PCA\n",
        "# ---------------------------\n",
        "# Retain 95% variance\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 4: Train Linear Regression and Calculate MAE\n",
        "# ---------------------------\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "train_preds = model.predict(X_train_pca)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on cleaned training set (with PCA): {mae:.2f}\")\n",
        "\n",
        "\n",
        "test_preds = model.predict(X_test_pca)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "id": "h5UTI1djUxz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d975a29-971a-4259-859b-efb1a27c6779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on cleaned training set (with PCA): 308.61\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using AdaBoost Regressor**"
      ],
      "metadata": {
        "id": "VHosqYKR_Su3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training and test data\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Initialize AdaBoost Regressor with a Decision Tree base estimator\n",
        "model = AdaBoostRegressor(\n",
        "    estimator=DecisionTreeRegressor(max_depth=4),\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training set and calculate MAE\n",
        "train_preds = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on training set (AdaBoost): {mae:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evmdjGPjWUAG",
        "outputId": "9e32fbb6-9e1c-4ca8-eb98-6cccf9a1d8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on training set (AdaBoost): 413.64\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Ridge Regression**"
      ],
      "metadata": {
        "id": "MrFYvUtC_Ynz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training and test data\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Standardize features (important for Ridge Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train Ridge Regression model\n",
        "model = Ridge(alpha=1.0, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on training set and compute MAE\n",
        "train_preds = model.predict(X_train_scaled)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on training set (Ridge): {mae:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz-clnVkWUDG",
        "outputId": "fdfafa1d-eff6-4ed2-905a-0be8048ae61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on training set (Ridge): 272.01\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LGBM Regressor Model**"
      ],
      "metadata": {
        "id": "oDx_Evtb_fH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training and test data\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Initialize LightGBM Regressor\n",
        "model = LGBMRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training data and calculate MAE\n",
        "train_preds = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on training set (LightGBM): {mae:.2f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "# Save predictions\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFE01duqWUF6",
        "outputId": "9d181861-79aa-4896-c911-317586219dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 850\n",
            "[LightGBM] [Info] Number of data points in the train set: 15000, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 6007.246244\n",
            "Mean Absolute Error on training set (LightGBM): 227.03\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Decision Tree Model**"
      ],
      "metadata": {
        "id": "CbYOm4DM_kFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training and test data\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Initialize and train Decision Tree Regressor\n",
        "model = DecisionTreeRegressor(max_depth=None, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training set and calculate MAE\n",
        "train_preds = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on training set (Decision Tree): {mae:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "# Save predictions to CSV\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBsZj8ZMWUIs",
        "outputId": "0257dd30-7307-40d9-ae0d-3c63d88831e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on training set (Decision Tree): 0.00\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using KNN model**"
      ],
      "metadata": {
        "id": "4SubWmnC_oAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Standardize features (important for KNN)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train KNN Regressor\n",
        "model = KNeighborsRegressor(n_neighbors=5)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on training data and calculate MAE\n",
        "train_preds = model.predict(X_train_scaled)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on training set (KNN): {mae:.2f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSOjWt8pWULp",
        "outputId": "4574aaeb-14c3-4ed3-eb92-729e41644f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on training set (KNN): 270.11\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Random Forest Regressor with PCA and Outlier removal**"
      ],
      "metadata": {
        "id": "eHPgmE-6_xta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# -----------------------------\n",
        "# Step 1: Remove Outliers using Z-score\n",
        "# -----------------------------\n",
        "train_clean = train_df.copy()\n",
        "X_raw = train_clean.drop(columns=['id', 'Row#', 'yield'])\n",
        "z_scores = np.abs(zscore(X_raw))\n",
        "\n",
        "# Keep rows where all z-scores are < 3\n",
        "train_clean = train_clean[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "# -----------------------------\n",
        "# Step 2: Prepare Features\n",
        "# -----------------------------\n",
        "X_train = train_clean.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_clean['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# -----------------------------\n",
        "# Step 3: Scale and Apply PCA\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "train_preds = model.predict(X_train_pca)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on cleaned training set (RF + PCA): {mae:.2f}\")\n",
        "\n",
        "test_preds = model.predict(X_test_pca)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcv9g3mYdfWk",
        "outputId": "a093a809-222c-4860-99a6-ed5783a324cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on cleaned training set (RF + PCA): 117.81\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Orthagonal Matching Pursuit**"
      ],
      "metadata": {
        "id": "-Xe4vRsF_7Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Standardize features (OMP is sensitive to scale)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train Orthogonal Matching Pursuit\n",
        "model = OrthogonalMatchingPursuit()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and compute MAE\n",
        "train_preds = model.predict(X_train_scaled)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on training set (OMP): {mae:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Save to CSV\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gThLjMvbd_HP",
        "outputId": "178a3511-c060-4ef9-d6d1-24bf661c99c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on training set (OMP): 282.48\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LGBM with Hypertuned parameters**"
      ],
      "metadata": {
        "id": "1Ln62-vnAFIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# OPTIONAL: Standardize (LightGBM doesn't require it but can help in some cases)\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "# --------------------------\n",
        "# Define and train LGBM model with tuned hyperparameters\n",
        "# --------------------------\n",
        "model = LGBMRegressor(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    min_child_samples=20,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --------------------------\n",
        "# Evaluate on training data\n",
        "# --------------------------\n",
        "train_preds = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error on training set (LGBM with hyperparams): {mae:.2f}\")\n",
        "\n",
        "# --------------------------\n",
        "# Predict on test set\n",
        "# --------------------------\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "# Save predictions\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Test predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVqIJ3E8euJL",
        "outputId": "3967a889-4888-4811-c4ef-29dc7fa62553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 850\n",
            "[LightGBM] [Info] Number of data points in the train set: 15000, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 6007.246244\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Mean Absolute Error on training set (LGBM with hyperparams): 231.72\n",
            "Test predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LGBM with PCA and Outlier Removal**"
      ],
      "metadata": {
        "id": "CX1Klx53AgnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Step 1: Remove Outliers using Z-score\n",
        "X_raw = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "z_scores = np.abs(zscore(X_raw))\n",
        "train_clean = train_df[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "# Step 2: Prepare Features\n",
        "X_train = train_clean.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_clean['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Step 3: Scale and Apply PCA\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Step 4: Train LGBM and Calculate MAE\n",
        "model = LGBMRegressor(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "train_preds = model.predict(X_train_pca)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"MAE on training set with PCA and outlier removal: {mae:.2f}\")\n",
        "\n",
        "# Step 5: Predict and Save\n",
        "test_preds = model.predict(X_test_pca)\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_lgbm_pca_outliers.csv\", index=False)\n",
        "print(\"Predictions saved to submission_lgbm_pca_outliers.csv\")\n"
      ],
      "metadata": {
        "id": "3C69zoQVeuOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f99e77f-2378-49cf-d22f-e3f460a34646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1530\n",
            "[LightGBM] [Info] Number of data points in the train set: 14860, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 6029.541639\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE on training set with PCA and outlier removal: 265.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to submission_lgbm_pca_outliers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Bayesian Ridge Model**"
      ],
      "metadata": {
        "id": "A07jXFwNAlxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X_train = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y_train = train_df['yield']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'], errors='ignore')\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Bayesian Ridge Regressor\n",
        "model = BayesianRidge()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "train_preds = model.predict(X_train_scaled)\n",
        "mae = mean_absolute_error(y_train, train_preds)\n",
        "print(f\"Mean Absolute Error (Bayesian Ridge): {mae:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Save predictions to CSV\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'yield': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_bayesian_ridge.csv\", index=False)\n",
        "print(\"Predictions saved to submission_bayesian_ridge.csv\")\n"
      ],
      "metadata": {
        "id": "tRdKqdmBeuRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4c347a-0a2c-476f-bcf0-50534f6fc603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (Bayesian Ridge): 272.01\n",
            "Predictions saved to submission_bayesian_ridge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using All Models with PCA and Outlier Removal**"
      ],
      "metadata": {
        "id": "G-Vl8i-TAqJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run the model evaluation pipeline for the re-uploaded files\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor, BayesianRidge\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit, LassoLars\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from lightgbm import LGBMRegressor\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Drop identifiers\n",
        "X = train_df.drop(columns=['id', 'Row#', 'yield'])\n",
        "y = train_df['yield']\n",
        "\n",
        "# Outlier removal using Z-score\n",
        "z_scores = np.abs(zscore(X))\n",
        "X_clean = X[(z_scores < 3).all(axis=1)]\n",
        "y_clean = y[X_clean.index]\n",
        "\n",
        "# Model dictionary\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(alpha=1.0),\n",
        "    \"Lasso\": Lasso(alpha=0.1),\n",
        "    \"BayesianRidge\": BayesianRidge(),\n",
        "    \"HuberRegressor\": HuberRegressor(),\n",
        "    \"OrthogonalMatchingPursuit\": OrthogonalMatchingPursuit(),\n",
        "    \"LassoLars\": LassoLars(),\n",
        "    \"DecisionTree\": DecisionTreeRegressor(max_depth=10),\n",
        "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, random_state=42),\n",
        "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
        "    \"LGBM\": LGBMRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "    pipeline.fit(X_clean, y_clean)\n",
        "    preds = pipeline.predict(X_clean)\n",
        "    mae = mean_absolute_error(y_clean, preds)\n",
        "    results.append({\"Model\": name, \"MAE (Train)\": round(mae, 2)})\n",
        "\n",
        "# Create results table\n",
        "results_df = pd.DataFrame(results).sort_values(by=\"MAE (Train)\").reset_index(drop=True)\n",
        "results_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eJj05GKjG-yd",
        "outputId": "3d1166f2-597d-4969-d7c8-666a9fa57914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1530\n",
            "[LightGBM] [Info] Number of data points in the train set: 14860, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 6029.541639\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model  MAE (Train)\n",
              "0                RandomForest       117.81\n",
              "1                        LGBM       265.45\n",
              "2                DecisionTree       266.72\n",
              "3                         KNN       273.87\n",
              "4              HuberRegressor       305.87\n",
              "5               BayesianRidge       308.61\n",
              "6            LinearRegression       308.61\n",
              "7                       Ridge       308.61\n",
              "8                       Lasso       308.61\n",
              "9                   LassoLars       308.67\n",
              "10                   AdaBoost       471.01\n",
              "11  OrthogonalMatchingPursuit       472.61"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ade4b2b7-e225-415d-8f7b-09beeb8f0118\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE (Train)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>117.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>265.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>266.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNN</td>\n",
              "      <td>273.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HuberRegressor</td>\n",
              "      <td>305.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BayesianRidge</td>\n",
              "      <td>308.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LinearRegression</td>\n",
              "      <td>308.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ridge</td>\n",
              "      <td>308.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Lasso</td>\n",
              "      <td>308.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LassoLars</td>\n",
              "      <td>308.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>471.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>OrthogonalMatchingPursuit</td>\n",
              "      <td>472.61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ade4b2b7-e225-415d-8f7b-09beeb8f0118')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ade4b2b7-e225-415d-8f7b-09beeb8f0118 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ade4b2b7-e225-415d-8f7b-09beeb8f0118');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4e1364e4-b64f-4478-83de-f584869e6756\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e1364e4-b64f-4478-83de-f584869e6756')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4e1364e4-b64f-4478-83de-f584869e6756 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6b35fd89-e21e-47ba-8cc0-e36d5441393c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b35fd89-e21e-47ba-8cc0-e36d5441393c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"AdaBoost\",\n          \"LassoLars\",\n          \"RandomForest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE (Train)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 92.68321908113909,\n        \"min\": 117.81,\n        \"max\": 472.61,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          471.01,\n          265.45,\n          308.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlbOp3t3G_Ak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}